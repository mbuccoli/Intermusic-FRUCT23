\section{Framework}\label{sec:framework}
We design the architecture of the experimental framework that we will use during the project for conducting perceptual experiments. We identify the following entities that can interact together in numerous way. A \textbf{performance} occurs when two or more \textbf{subjects} interact together through a \textbf{medium}. Subjects can be musicians during a rehearse, as well as teacher and student for a front lesson. Subjects interact from an \textbf{environment}, that is, the physical location where they perform, which has their own timbral (acoustic of the room) and spatial properties (location of the subjects in the room). If the environments are different, the subjects will interact through a \textit{networked medium}, hence having a NMP; otherwise they interact through a \textit{physical medium}. The comparison between a networked and physical medium is crucial to understand how to design the interaction so that the \textit{virtual environment} perceived from the other end of the medium matches the expectations of a real environment. In order to analyze the performance, it is crucial to run an \textbf{acquisition} stage, using different devices to capture the multimodal signals. The factors and aspects that will be possible to analyze from the performance depend on the properties of the devices, e.g., whether they are \textit{video} or \textit{audio devices}, or where they are placed. In the following sections we describe in detail the aforementioned entities.

\subsection{Performance}
The performance is the entity at the highest hierarchical level, since it is defined as the composition of the subjects, the environment and the medium. 
Properties of the performance include date and time, location(s), and the \textit{performed piece} or \textit{taught lesson}, that is better detailed in the subjects' \textit{part} property. Beyond the metadata (e.g., composer of the piece, tempo, meter, key signature, score, duration, etc.), we can extract a content-based description from its symbolic representation (MIDI or musicXML) \cite{MIDItoolbox}.

Some properties of the performance depend on the nature of its sub-entities. For example, if the subjects are two musicians, the performance can be a \textit{rehearsal} or a \textit{concert}, while if one of the subject is a teacher, the performance is defined as a \textit{lesson}. As discussed above, the property of performance also depends on the type of medium (physical or networked).  

\subsection{Subjects}
Subjects are involved in the performance with different possible roles, such as musicians, students, teachers or conductors. Subjects are identified with their name, age, experience, musical background, that evolve over time and so must be referred to the day of the performance. Other properties inherently related to a subject is the assigned part -what they are performing- and the used instrument. These two properties can be also described by means of a content-based analysis of their musicological (e.g., rhythmic complexity) or timbral (e.g. attack time) properties, respectively \cite{RottondiFeature}.
Doing this, it is possible to analyze how such properties as aspects that may affect the final quality or success of the performance.


\subsection{Environment}
We refer to the spatial and acoustic properties of both the physical place where a subject performs and the perception of it by the other subjects as physical and virtual environment, respectively. The properties of the virtual environment depend on (and, therefore, include) the location and specifics of the audio/video acquisition and rendering devices, as well as the possible processing applied to the audio or video signals. For example, using an array of microphones we can %acquire a planar sound field of the environment and render it using an array of speakers using techniques for spatial audio [CIT]. 
analyze the acoustic scene~\cite{Markovic2013} and render it using arrays of speakers through spatial audio techniques~\cite{bianchi2016}.

We also collect the information about the interaction of the subjects with the environment, such as the position of the musicians in the room, the details of the audio/video acquisition (e.g., microphone on the instrument vs. fixed position microphone) and the relative position of musician and devices. 

\subsection{Medium}
The medium refers to the connection between the environments and, hence, the subjects. In case of a networked performance, the medium collects the information on the employed software for NMP and its settings, the network architecture and specifics, like bandwidth, latency. In case of a performance in the same room, like a traditional lesson, we collect information as the distance between the subjects, which measures the acoustic latency between them, and describe possible visual / acoustic occlusion that may be placed between the musicians. 

\subsection{Acquisition}
In order to observe the experiment and draw meaningful conclusions, we need to acquire the outcome that are interesting for our analysis. For the acquisition stage, we consider multimodal signals and their processing byproduct as well as questionnaire filled by the subjects. In the former case we can extract objective metrics of the performance, while in the latter we consider subjective results; both are important to assess the outcome of the experiment. 

With regard to the multimodal signals, the audio recording of the performance, from the two environments, are clearly useful to assess the quality of the performance or possible modifications in the timbral or rhythmic properties. Beyond that, video recordings are also useful to annotate saccadic movement during the interaction between the subjects [CIT], and we aim to capture biometric signals to objectively estimate the subjective distress of the performers [CIT]. 
